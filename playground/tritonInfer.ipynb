{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dc49d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as tritonhttpclient\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import onnxruntime as rt\n",
    "import tritonclient.grpc as client\n",
    "import torch\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abb5f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInferencer():\n",
    "    def __init__(self, model_name:str, engine:str = 'triton', url:str=None):\n",
    "        self.engine = engine\n",
    "        self.model_name = model_name\n",
    "        self.url = url\n",
    "        with open('imagenet-idx.txt') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "        self.labels = classes\n",
    "        if self.engine == 'onnxruntime' or self.engine == 'onnxruntime-gpu':\n",
    "            sessOpt = rt.SessionOptions()\n",
    "            sessOpt.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "            sessOpt.add_session_config_entry(\"session.set_denormal_as_zero\", \"1\")\n",
    "            \n",
    "            if self.engine == 'onnxruntime':\n",
    "                providers=['CPUExecutionProvider']\n",
    "            else:\n",
    "                providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "\n",
    "            self.inferencer = rt.InferenceSession(self.model_name, sessOpt, providers=providers)\n",
    "        elif self.engine == 'triton':\n",
    "            self.tritonConnector = client.InferenceServerClient(url=self.url)\n",
    "    \n",
    "    def infer(self, image_numpy):\n",
    "        if self.engine == 'onnxruntime' or self.engine == 'onnxruntime-gpu':\n",
    "            input_batch = self.preprocess(image_numpy)\n",
    "            onnx_output = self.inferencer.run(None, {'input' : input_batch})\n",
    "            onnx_output = torch.FloatTensor(np.array(onnx_output)).reshape(1,-1)\n",
    "            results = self.postprocess(onnx_output)\n",
    "        elif self.engine == 'triton':\n",
    "            input_batch = self.preprocess(image_numpy)\n",
    "            input0 = client.InferInput('input', (1, 3, 224, 224), \"FP16\")\n",
    "            input0.set_data_from_numpy(input_batch)\n",
    "            output = self.tritonConnector.infer(model_name=self.model_name, inputs=[input0])\n",
    "            logits = output.as_numpy('output') \n",
    "            results = self.postprocess(logits)\n",
    "        return results\n",
    "        \n",
    "    def preprocess(self, image_numpy):\n",
    "        transform = A.Compose(\n",
    "                [\n",
    "                    A.Resize(height=224, width=224),\n",
    "                    A.Normalize(\n",
    "                        mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225],\n",
    "                        max_pixel_value=255., \n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    ToTensorV2(),\n",
    "                ])\n",
    "        transform = transform(image=image_numpy)\n",
    "        image = transform[\"image\"]\n",
    "        input_batch = image.unsqueeze(0).numpy()\n",
    "        \n",
    "        if self.engine == 'onnxruntime' or self.engine == 'onnxruntime-gpu':\n",
    "            input_batch = input_batch.astype(np.float32)\n",
    "        if self.engine == 'triton':\n",
    "            input_batch = input_batch.astype(np.float16)\n",
    "        return input_batch\n",
    "        \n",
    "    def postprocess(self, output, topK=10):\n",
    "        if self.engine == 'onnxruntime' or self.engine == 'onnxruntime-gpu':\n",
    "            onnx_output = output\n",
    "            onnx_output = torch.FloatTensor(np.array(onnx_output)).reshape(1,-1)\n",
    "            prob = torch.nn.functional.softmax(onnx_output, dim=1)[0] * 100\n",
    "            _, indices = torch.sort(prob, descending=True)\n",
    "            return [(self.labels[idx], prob[idx].item()) for idx in indices[:topK]]\n",
    "        elif self.engine == 'triton':\n",
    "            triton_output = output\n",
    "            logits = np.asarray(triton_output, dtype=np.float32)\n",
    "            probs = softmax(logits)\n",
    "            probs = np.sort(probs).reshape(-1)[::-1] * 100\n",
    "            indices = np.argsort(logits).reshape(-1)[::-1]\n",
    "            zipped = list(zip(indices,probs))\n",
    "            return [(self.labels[elem[0]], elem[1]) for elem in zipped[:topK]]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a60d1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images\\\\standard.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68a1948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tritonInferencer = ModelInferencer(model_name='resnet18_trt', engine='triton', url='localhost:8001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34e8faa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standard poodle', 73.42017),\n",
       " ('Bedlington terrier', 22.744509),\n",
       " ('miniature poodle', 2.3785977),\n",
       " ('toy poodle', 0.6922115),\n",
       " ('Kerry blue terrier', 0.31940314),\n",
       " ('komondor', 0.15688553),\n",
       " ('Afghan hound, Afghan', 0.0944154),\n",
       " ('Irish water spaniel', 0.08075776),\n",
       " ('Lakeland terrier', 0.021566508),\n",
       " ('soft-coated wheaten terrier', 0.01181747)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = tritonInferencer.infer(image)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96fa388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxInferencer = ModelInferencer(model_name='model_repository\\\\resnet18_trt\\\\1\\\\model.onnx', \n",
    "                                  engine='onnxruntime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e2f422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('standard poodle', 73.5542221069336),\n",
       " ('Bedlington terrier', 22.600780487060547),\n",
       " ('miniature poodle', 2.38507342338562),\n",
       " ('toy poodle', 0.6931744813919067),\n",
       " ('Kerry blue terrier', 0.3209385871887207),\n",
       " ('komondor', 0.1573612540960312),\n",
       " ('Afghan hound, Afghan', 0.09467097371816635),\n",
       " ('Irish water spaniel', 0.08072715997695923),\n",
       " ('Lakeland terrier', 0.021591916680336),\n",
       " ('soft-coated wheaten terrier', 0.011789900250732899)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxInferencer.infer(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5ba8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a8a81ff5d755b15bad9772d7c59b5f150b144c443f5da213845dae9e79d687b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
